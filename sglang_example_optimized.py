#!/usr/bin/env python3
"""
SGLang ç»Ÿä¸€æµ‹è¯•ç¤ºä¾‹ - æœ€ç»ˆä¼˜åŒ–ç‰ˆæœ¬
æ•´åˆ SGLang Python API å’Œ OpenAI SDK çš„æœ€ä½³å®è·µ
"""

import sglang as sgl
import requests
import json
from openai import OpenAI

# OpenAI SDK å®¢æˆ·ç«¯é…ç½®
openai_client = OpenAI(
    api_key="EMPTY",
    base_url="http://localhost:30000/v1",
)

def safe_get_content(response) -> str:
    """å®‰å…¨è·å–å“åº”å†…å®¹"""
    content = response.choices[0].message.content
    return content if content is not None else ""

@sgl.function
def simple_qa(s, question):
    """ç®€å•é—®ç­”ç¤ºä¾‹ - ä¸­æ–‡ç³»ç»Ÿæç¤ºè¯ + ä¼˜åŒ–å‚æ•°"""
    s += sgl.system("ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚")  # type: ignore
    s += sgl.user(question)  # type: ignore
    s += sgl.assistant(sgl.gen("answer", temperature=0.7, top_p=0.8, presence_penalty=1.5, stop=["<think>", "</think>", "æ€è€ƒ:", "ç”¨æˆ·:", "ASSISTANT:"]))

def openai_chat_clean(messages, max_tokens=200):
    """OpenAI SDK æ¸…æ´è°ƒç”¨ - ä½¿ç”¨ enable_thinking: False"""
    try:
        response = openai_client.chat.completions.create(
            model="default",
            messages=messages,
            max_tokens=max_tokens,
            temperature=0.7,
            top_p=0.8,
            presence_penalty=1.5,
            extra_body={
                "top_k": 20,
                "chat_template_kwargs": {"enable_thinking": False},  # å…³é”®å‚æ•°
            },
        )
        return safe_get_content(response)
    except Exception as e:
        return f"Exception: {e}"

def chat_api_clean(messages, max_tokens=200):
    """ä¼ ç»Ÿ requests è°ƒç”¨ - ä½¿ç”¨ enable_thinking: False"""
    url = "http://localhost:30000/v1/chat/completions"
    
    payload = {
        "model": "default",
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": 0.7,
        "top_p": 0.8,
        "presence_penalty": 1.5,
        "extra_body": {
            "top_k": 20,
            "chat_template_kwargs": {
                "enable_thinking": False  # å…³é”®å‚æ•°ï¼šç¦ç”¨æ€è€ƒè¿‡ç¨‹
            }
        }
    }
    
    try:
        response = requests.post(url, json=payload, timeout=30)
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            return content if content is not None else ""
        else:
            return f"Error: {response.status_code}"
    except Exception as e:
        return f"Exception: {e}"

def openai_structured_generation(topic):
    """OpenAI SDK ç»“æ„åŒ–ç”Ÿæˆ - æ¨èæ–¹å¼"""
    try:
        response = openai_client.chat.completions.create(
            model="default",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œè¯·æŒ‰ç…§æŒ‡å®šæ ¼å¼æä¾›ä¿¡æ¯ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚"},
                {"role": "user", "content": f"è¯·ç®€è¦ä»‹ç»{topic}ï¼ŒåŒ…æ‹¬å®šä¹‰å’Œä¸»è¦ç‰¹ç‚¹ã€‚è¯·åˆ†åˆ«ç”¨'å®šä¹‰ï¼š'å’Œ'ç‰¹ç‚¹ï¼š'å¼€å¤´ï¼Œæ¯éƒ¨åˆ†ç”¨ä¸€æ®µè¯è¯´æ˜ã€‚"}
            ],
            max_tokens=300,
            temperature=0.5,
            top_p=0.8,
            presence_penalty=1.5,
            extra_body={
                "top_k": 20,
                "chat_template_kwargs": {"enable_thinking": False},
            },
        )
        return safe_get_content(response)
    except Exception as e:
        return f"Exception: {e}"

@sgl.function
def structured_generation(s, topic):
    """ç»“æ„åŒ–ç”Ÿæˆç¤ºä¾‹ - SGLang APIï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
    s += sgl.system("ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œè¯·æŒ‰ç…§æŒ‡å®šæ ¼å¼æä¾›ä¿¡æ¯ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚")  # type: ignore
    s += sgl.user(f"è¯·ç®€è¦ä»‹ç»{topic}ï¼ŒåŒ…æ‹¬å®šä¹‰å’Œä¸»è¦ç‰¹ç‚¹ã€‚è¯·åˆ†åˆ«ç”¨'å®šä¹‰ï¼š'å’Œ'ç‰¹ç‚¹ï¼š'å¼€å¤´ã€‚")  # type: ignore
    s += sgl.assistant("å®šä¹‰ï¼š")  # type: ignore
    s += sgl.assistant(sgl.gen("definition", temperature=0.5, top_p=0.8, presence_penalty=1.5, stop=["<think>", "</think>", "\nç‰¹ç‚¹ï¼š", "\n\n"]))
    s += sgl.assistant("\nç‰¹ç‚¹ï¼š")  # type: ignore
    s += sgl.assistant(sgl.gen("features", temperature=0.5, top_p=0.8, presence_penalty=1.5, stop=["<think>", "</think>", "\nå®šä¹‰ï¼š", "\n\n"]))

@sgl.function
def creative_writing(s, prompt):
    """åˆ›ä½œç¤ºä¾‹ - ä¸­æ–‡ç³»ç»Ÿæç¤ºè¯ç‰ˆ"""
    s += sgl.system("ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„ä½œå®¶ï¼Œè¯·ç›´æ¥æä¾›åˆ›ä½œå†…å®¹ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚")  # type: ignore
    s += sgl.user(prompt)  # type: ignore
    s += sgl.assistant(sgl.gen("content", temperature=0.8, top_p=0.9, presence_penalty=1.5, stop=["<think>", "</think>", "---", "END"]))

@sgl.function
def code_generation(s, task):
    """ä»£ç ç”Ÿæˆç¤ºä¾‹ - ä¸­æ–‡ç³»ç»Ÿæç¤ºè¯ç‰ˆ"""
    s += sgl.system("ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹ä¸“å®¶ï¼Œè¯·ç›´æ¥æä¾›ä»£ç ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹å’Œè§£é‡Šã€‚")  # type: ignore
    s += sgl.user(f"è¯·ç¼–å†™ä»£ç ï¼š{task}")  # type: ignore
    s += sgl.assistant("```python\n")  # type: ignore
    s += sgl.assistant(sgl.gen("code", temperature=0.3, top_p=0.8, presence_penalty=1.5, stop=["```", "<think>", "</think>", "END"]))
    s += sgl.assistant("\n```")  # type: ignore

def main():
    # è®¾ç½®åç«¯åœ°å€
    sgl.set_default_backend(sgl.RuntimeEndpoint("http://localhost:30000"))
    
    print("=" * 80)
    print("ğŸš€ SGLang ç»Ÿä¸€æµ‹è¯•ç¤ºä¾‹ï¼ˆæœ€ç»ˆä¼˜åŒ–ç‰ˆï¼‰")
    print("æ•´åˆ SGLang Python API å’Œ OpenAI SDK çš„æœ€ä½³å®è·µ")
    print("=" * 80)
    
    # ç¤ºä¾‹1: SGLang Python API é—®ç­”
    print("\n1. ğŸ¯ SGLang Python API é—®ç­”")
    print("-" * 50)
    try:
        state = simple_qa.run(question="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")
        print(f"é—®é¢˜: ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")
        print(f"å›ç­”: {state['answer'].strip()}")
        print("âœ… SGLang API æˆåŠŸ - è¾“å‡ºå¹²å‡€")
    except Exception as e:
        print(f"âŒ SGLang API å¤±è´¥: {e}")
    
    # ç¤ºä¾‹2: OpenAI SDK æµ‹è¯•ï¼ˆæ¨èæ–¹å¼ï¼‰
    print("\n2. ğŸ”¥ OpenAI SDK æµ‹è¯•ï¼ˆæ¨è - enable_thinking: Falseï¼‰")
    print("-" * 50)
    try:
        result = openai_chat_clean([
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚"},
            {"role": "user", "content": "ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ï¼Ÿè¯·ç®€æ´å›ç­”ã€‚"}
        ])
        print(f"é—®é¢˜: ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ï¼Ÿ")
        print(f"å›ç­”: {result.strip()}")
        print("âœ… OpenAI SDK æˆåŠŸ")
    except Exception as e:
        print(f"âŒ OpenAI SDK å¤±è´¥: {e}")
    
    # ç¤ºä¾‹3: ä¼ ç»Ÿ requests è°ƒç”¨å¯¹æ¯”
    print("\n3. ğŸ’¬ ä¼ ç»Ÿ requests è°ƒç”¨å¯¹æ¯”")
    print("-" * 50)
    try:
        result = chat_api_clean([
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚"},
            {"role": "user", "content": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿè¯·ç®€æ´å›ç­”ã€‚"}
        ])
        print(f"é—®é¢˜: ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
        print(f"å›ç­”: {result.strip()}")
        print("âœ… requests è°ƒç”¨æˆåŠŸ")
    except Exception as e:
        print(f"âŒ requests è°ƒç”¨å¤±è´¥: {e}")
    
    # ç¤ºä¾‹4: ç»“æ„åŒ–ç”Ÿæˆï¼ˆOpenAI SDK - æ¨èï¼‰
    print("\n4. ğŸ“Š ç»“æ„åŒ–ç”Ÿæˆæµ‹è¯•ï¼ˆOpenAI SDKï¼‰")
    print("-" * 50)
    try:
        result = openai_structured_generation("æ·±åº¦å­¦ä¹ ")
        print(f"ä¸»é¢˜: æ·±åº¦å­¦ä¹ ")
        print(f"ç»“æœ: {result}")
        print("âœ… OpenAI SDK ç»“æ„åŒ–ç”ŸæˆæˆåŠŸ")
    except Exception as e:
        print(f"âŒ OpenAI SDK ç»“æ„åŒ–ç”Ÿæˆå¤±è´¥: {e}")
    
    # ç¤ºä¾‹4B: SGLang API ç»“æ„åŒ–ç”Ÿæˆï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
    print("\n4B. ğŸ“Š SGLang API ç»“æ„åŒ–ç”Ÿæˆï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰")
    print("-" * 50)
    try:
        state = structured_generation.run(topic="æœºå™¨å­¦ä¹ ")
        print(f"ä¸»é¢˜: æœºå™¨å­¦ä¹ ")
        print(f"å®šä¹‰: {state['definition'].strip()}")
        print(f"ç‰¹ç‚¹: {state['features'].strip()}")
        print("âœ… SGLang API ç»“æ„åŒ–ç”ŸæˆæˆåŠŸ")
    except Exception as e:
        print(f"âŒ SGLang API ç»“æ„åŒ–ç”Ÿæˆå¤±è´¥: {e}")
    
    # ç¤ºä¾‹5: åˆ›æ„å†™ä½œï¼ˆSGLang APIï¼‰
    print("\n5. âœï¸ åˆ›æ„å†™ä½œæµ‹è¯•")
    print("-" * 50)
    try:
        state = creative_writing.run(prompt="å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„å››è¡Œè¯—")
        print(f"è¦æ±‚: å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„å››è¡Œè¯—")
        content = state['content'].strip()
        print(f"ä½œå“: {content}")
        print("âœ… SGLang åˆ›æ„å†™ä½œæˆåŠŸ")
    except Exception as e:
        print(f"âŒ SGLang åˆ›æ„å†™ä½œå¤±è´¥: {e}")
    
    # ç¤ºä¾‹6: ä»£ç ç”Ÿæˆï¼ˆSGLang APIï¼‰
    print("\n6. ğŸ’» ä»£ç ç”Ÿæˆæµ‹è¯•")
    print("-" * 50)
    try:
        state = code_generation.run(task="å®ç°å†’æ³¡æ’åº")
        print(f"ä»»åŠ¡: å®ç°å†’æ³¡æ’åº")
        print(f"ä»£ç :\n```python\n{state['code'].strip()}\n```")
        print("âœ… SGLang ä»£ç ç”ŸæˆæˆåŠŸ")
    except Exception as e:
        print(f"âŒ SGLang ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
    
    # ç¤ºä¾‹7: OpenAI SDK æ‰¹é‡æµ‹è¯•
    print("\n7. ğŸ”¥ OpenAI SDK æ‰¹é‡æµ‹è¯•ï¼ˆæ¨èæ–¹å¼ï¼‰")
    print("-" * 50)
    
    # å¤šç§é—®é¢˜ç±»å‹çš„æµ‹è¯•
    test_questions = [
        "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
        "è°å‘æ˜äº†ç”µè¯ï¼Ÿ", 
        "è§£é‡Šä¸€ä¸‹åŒºå—é“¾æŠ€æœ¯"
    ]
    
    for i, q in enumerate(test_questions, 1):
        try:
            result = openai_chat_clean([
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚"},
                {"role": "user", "content": q}
            ])
            print(f"7.{i} {q}")
            print(f"    ç­”: {result[:80]}..." if len(result) > 80 else f"    ç­”: {result}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ€è€ƒè¿‡ç¨‹æ ‡è®°
            has_thinking = any(marker in result for marker in ["<think>", "</think>", "æ€è€ƒ:", "ç”¨æˆ·é—®", "ASSISTANT:"])
            print(f"    {'âš ï¸  åŒ…å«æ€è€ƒæ ‡è®°' if has_thinking else 'âœ… å¹²å‡€è¾“å‡º'}")
        except Exception as e:
            print(f"    âŒ å¤±è´¥: {e}")
    
    # ç¤ºä¾‹8: å‚æ•°å¯¹æ¯”æµ‹è¯•
    print("\n8. âš–ï¸ enable_thinking å‚æ•°å¯¹æ¯”æµ‹è¯•")
    print("-" * 50)
    
    test_question = "ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ"
    
    # æµ‹è¯•ä¸å¸¦ enable_thinking=False çš„æƒ…å†µ
    print("ğŸ”¸ ä¸ä½¿ç”¨ enable_thinking=False:")
    try:
        # åˆ›å»ºä¸€ä¸ªä¸ä½¿ç”¨ enable_thinking=False çš„ä¸´æ—¶å‡½æ•°
        payload_without_enable_thinking = {
            "model": "default",
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": test_question}
            ],
            "max_tokens": 300,
            "temperature": 0.7,
            "top_p": 0.8,
            "presence_penalty": 1.5,
        }
        
        response = requests.post("http://localhost:30000/v1/chat/completions", 
                               json=payload_without_enable_thinking, timeout=30)
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            result1 = content if content is not None else ""
        else:
            result1 = f"Error: {response.status_code}"
            
        print(f"    å›ç­”: {result1[:100]}..." if len(result1) > 100 else f"    å›ç­”: {result1}")
        has_thinking1 = "<think>" in result1 or "</think>" in result1
        print(f"    {'åŒ…å«æ€è€ƒè¿‡ç¨‹' if has_thinking1 else 'å¹²å‡€è¾“å‡º'}")
    except Exception as e:
        print(f"    âŒ å¤±è´¥: {e}")
    
    print("\nğŸ”¸ ä½¿ç”¨ enable_thinking=False:")
    try:
        result2 = openai_chat_clean([
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚"},
            {"role": "user", "content": test_question}
        ], max_tokens=300)
        print(f"    å›ç­”: {result2[:100]}..." if len(result2) > 100 else f"    å›ç­”: {result2}")
        has_thinking2 = "<think>" in result2 or "</think>" in result2
        print(f"    {'åŒ…å«æ€è€ƒè¿‡ç¨‹' if has_thinking2 else 'âœ… å¹²å‡€è¾“å‡º'}")
    except Exception as e:
        print(f"    âŒ å¤±è´¥: {e}")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ ç»Ÿä¸€æµ‹è¯•å®Œæˆ")
    print("ğŸ† æœ€ä½³å®è·µæ€»ç»“ï¼š")
    print("   1. ğŸ”¥ æ¨èä½¿ç”¨ OpenAI SDK + enable_thinking: False")
    print("   2. ğŸ’¡ é…åˆä¸­æ–‡ç³»ç»Ÿæç¤ºè¯ï¼š'ä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹'")
    print("   3. âš™ï¸  æ¨èå‚æ•°: temperature=0.7, top_p=0.8, presence_penalty=1.5")
    print("   4. ğŸ“ max_tokens å»ºè®®è®¾ç½®ä¸º 150-400 å¯¹äºç®€çŸ­å›ç­”")
    print("   5. ğŸ› ï¸  SGLang API æ·»åŠ  stop åºåˆ—: ['<think>', '</think>', 'æ€è€ƒ:', 'ç”¨æˆ·:', 'ASSISTANT:']")
    print("   6. ğŸ¯ OpenAI SDK åœ¨ extra_body ä¸­ä½¿ç”¨ chat_template_kwargs")
    print("   7. âœ¨ OpenAI SDK æä¾›æ›´å¥½çš„ç±»å‹å®‰å…¨æ€§å’Œæ˜“ç”¨æ€§")
    print("=" * 80)

if __name__ == "__main__":
    main() 