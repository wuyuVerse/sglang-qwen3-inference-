#!/usr/bin/env python3
"""
OpenAI SDK æ¥å£æµ‹è¯• - ä¸“é—¨æµ‹è¯•å¦‚ä½•é¿å…æ€è€ƒè¿‡ç¨‹è¾“å‡º
åŸºäº SGLang å®˜æ–¹æ–‡æ¡£çš„ç¤ºä¾‹ - ç±»å‹å®‰å…¨ç‰ˆæœ¬
"""

from openai import OpenAI
import json

# è®¾ç½® OpenAI å®¢æˆ·ç«¯è¿æ¥åˆ° SGLang æœåŠ¡å™¨
openai_api_key = "EMPTY"
openai_api_base = "http://localhost:30000/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

def safe_get_content(response) -> str:
    """å®‰å…¨è·å–å“åº”å†…å®¹"""
    content = response.choices[0].message.content
    return content if content is not None else ""

def test_enable_thinking_false():
    """æµ‹è¯• enable_thinking=False å‚æ•°"""
    print("ğŸ”´ æµ‹è¯• 1: enable_thinking=False")
    print("-" * 50)
    
    try:
        response = client.chat.completions.create(
            model="default",  # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚"},
                {"role": "user", "content": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿè¯·ç®€æ´å›ç­”ã€‚"}
            ],
            max_tokens=200,
            temperature=0.7,
            top_p=0.8,
            presence_penalty=1.5,
            extra_body={
                "top_k": 20,
                "chat_template_kwargs": {"enable_thinking": False},  # å…³é”®å‚æ•°
            },
        )
        
        content = safe_get_content(response)
        print(f"é—®é¢˜: ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")
        print(f"å›ç­”: {content}")
        print(f"âœ… æˆåŠŸ - è¾“å‡ºé•¿åº¦: {len(content)} å­—ç¬¦")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ€è€ƒè¿‡ç¨‹æ ‡è®°
        if "<think>" in content or "</think>" in content:
            print("âš ï¸  è­¦å‘Š: è¾“å‡ºä»åŒ…å«æ€è€ƒæ ‡è®°")
        else:
            print("âœ… æ— æ€è€ƒæ ‡è®°")
            
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
    
    print()

def test_enable_thinking_true():
    """æµ‹è¯• enable_thinking=True å‚æ•°ï¼ˆå¯¹æ¯”ï¼‰"""
    print("ğŸŸ¡ æµ‹è¯• 2: enable_thinking=True (å¯¹æ¯”æµ‹è¯•)")
    print("-" * 50)
    
    try:
        response = client.chat.completions.create(
            model="default",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿè¯·ç®€æ´å›ç­”ã€‚"}
            ],
            max_tokens=400,
            temperature=0.7,
            top_p=0.8,
            presence_penalty=1.5,
            extra_body={
                "top_k": 20,
                "chat_template_kwargs": {"enable_thinking": True},  # å¯ç”¨æ€è€ƒ
            },
        )
        
        content = safe_get_content(response)
        print(f"é—®é¢˜: ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")
        print(f"å›ç­”: {content[:200]}..." if len(content) > 200 else f"å›ç­”: {content}")
        print(f"ğŸ’­ è¾“å‡ºé•¿åº¦: {len(content)} å­—ç¬¦")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ€è€ƒè¿‡ç¨‹æ ‡è®°
        if "<think>" in content or "</think>" in content:
            print("ğŸ’­ åŒ…å«æ€è€ƒæ ‡è®°ï¼ˆé¢„æœŸè¡Œä¸ºï¼‰")
        else:
            print("â“ æœªåŒ…å«æ€è€ƒæ ‡è®°")
            
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
    
    print()

def test_different_models():
    """æµ‹è¯•ä¸åŒçš„æ¨¡å‹åç§°"""
    print("ğŸ”µ æµ‹è¯• 3: ä¸åŒæ¨¡å‹åç§°æµ‹è¯•")
    print("-" * 50)
    
    model_names = ["default", "Qwen/Qwen3-4B"]
    
    for model_name in model_names:
        print(f"ğŸ“ æµ‹è¯•æ¨¡å‹: {model_name}")
        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚"},
                    {"role": "user", "content": "è°å‘æ˜äº†ç”µè¯ï¼Ÿ"}
                ],
                max_tokens=150,
                temperature=0.7,
                top_p=0.8,
                presence_penalty=1.5,
                extra_body={
                    "chat_template_kwargs": {"enable_thinking": False},
                },
            )
            
            content = safe_get_content(response)
            print(f"   å›ç­”: {content}")
            print(f"   âœ… æˆåŠŸ")
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
        print()

def test_multiple_questions():
    """æ‰¹é‡æµ‹è¯•å¤šä¸ªé—®é¢˜"""
    print("ğŸŸ£ æµ‹è¯• 4: æ‰¹é‡é—®é¢˜æµ‹è¯• (enable_thinking=False)")
    print("-" * 50)
    
    questions = [
        "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
        "åŒºå—é“¾æŠ€æœ¯çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½çš„åŒºåˆ«ï¼Ÿ",
        "Python çš„ä¸»è¦ç‰¹ç‚¹ï¼Ÿ"
    ]
    
    for i, question in enumerate(questions, 1):
        try:
            response = client.chat.completions.create(
                model="default",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚"},
                    {"role": "user", "content": question}
                ],
                max_tokens=150,
                temperature=0.7,
                top_p=0.8,
                presence_penalty=1.5,
                extra_body={
                    "chat_template_kwargs": {"enable_thinking": False},
                },
            )
            
            content = safe_get_content(response)
            print(f"4.{i} {question}")
            print(f"    ç­”: {content[:100]}..." if len(content) > 100 else f"    ç­”: {content}")
            
            # æ£€æŸ¥æ€è€ƒæ ‡è®°
            has_thinking = any(marker in content for marker in ["<think>", "</think>", "æ€è€ƒ:", "ç”¨æˆ·é—®", "ASSISTANT:"])
            print(f"    {'âš ï¸  åŒ…å«æ€è€ƒæ ‡è®°' if has_thinking else 'âœ… å¹²å‡€è¾“å‡º'}")
            
        except Exception as e:
            print(f"4.{i} âŒ å¤±è´¥: {e}")
        print()

def test_parameter_optimization():
    """æµ‹è¯•å‚æ•°ä¼˜åŒ–ç»„åˆ"""
    print("ğŸŸ  æµ‹è¯• 5: å‚æ•°ä¼˜åŒ–ç»„åˆæµ‹è¯•")
    print("-" * 50)
    
    # æµ‹è¯•ä¸åŒçš„å‚æ•°ç»„åˆ
    test_configs = [
        {
            "name": "é…ç½®A: ä½åˆ›é€ æ€§",
            "params": {
                "temperature": 0.3,
                "top_p": 0.7,
                "presence_penalty": 2.0,
            }
        },
        {
            "name": "é…ç½®B: æ¨èå‚æ•°",
            "params": {
                "temperature": 0.7,
                "top_p": 0.8,
                "presence_penalty": 1.5,
            }
        },
        {
            "name": "é…ç½®C: é«˜åˆ›é€ æ€§",
            "params": {
                "temperature": 0.9,
                "top_p": 0.9,
                "presence_penalty": 1.0,
            }
        }
    ]
    
    question = "ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ"
    
    for config in test_configs:
        print(f"ğŸ“Š {config['name']}")
        try:
            response = client.chat.completions.create(
                model="default",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´æ˜äº†åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ã€‚"},
                    {"role": "user", "content": question}
                ],
                max_tokens=200,
                **config['params'],
                extra_body={
                    "chat_template_kwargs": {"enable_thinking": False},
                },
            )
            
            content = safe_get_content(response)
            print(f"   å›ç­”: {content[:80]}..." if len(content) > 80 else f"   å›ç­”: {content}")
            print(f"   é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # æ£€æŸ¥æ€è€ƒæ ‡è®°
            has_thinking = any(marker in content for marker in ["<think>", "</think>", "æ€è€ƒ:", "ç”¨æˆ·é—®", "ASSISTANT:"])
            print(f"   {'âš ï¸  åŒ…å«æ€è€ƒç›¸å…³å†…å®¹' if has_thinking else 'âœ… å¹²å‡€è¾“å‡º'}")
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
        print()

def test_comparison_with_without_enable_thinking():
    """å¯¹æ¯”æµ‹è¯•ï¼šå¸¦å’Œä¸å¸¦ enable_thinking å‚æ•°"""
    print("ğŸ”„ æµ‹è¯• 6: enable_thinking å‚æ•°å¯¹æ¯”æµ‹è¯•")
    print("-" * 50)
    
    question = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"
    
    # æµ‹è¯•ä¸å¸¦ enable_thinking å‚æ•°
    print("ğŸ”¹ ä¸ä½¿ç”¨ enable_thinking å‚æ•°:")
    try:
        response1 = client.chat.completions.create(
            model="default",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ],
            max_tokens=300,
            temperature=0.7,
            top_p=0.8,
        )
        
        content1 = safe_get_content(response1)
        print(f"   å›ç­”: {content1[:150]}..." if len(content1) > 150 else f"   å›ç­”: {content1}")
        print(f"   é•¿åº¦: {len(content1)} å­—ç¬¦")
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
    
    print()
    
    # æµ‹è¯•å¸¦ enable_thinking=False å‚æ•°
    print("ğŸ”¹ ä½¿ç”¨ enable_thinking=False:")
    try:
        response2 = client.chat.completions.create(
            model="default",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ],
            max_tokens=300,
            temperature=0.7,
            top_p=0.8,
            extra_body={
                "chat_template_kwargs": {"enable_thinking": False},
            },
        )
        
        content2 = safe_get_content(response2)
        print(f"   å›ç­”: {content2[:150]}..." if len(content2) > 150 else f"   å›ç­”: {content2}")
        print(f"   é•¿åº¦: {len(content2)} å­—ç¬¦")
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
    
    print()

def main():
    print("=" * 80)
    print("ğŸš€ OpenAI SDK æ¥å£æµ‹è¯• - é¿å…æ€è€ƒè¿‡ç¨‹è¾“å‡º")
    print("åŸºäº SGLang å®˜æ–¹æ–‡æ¡£ç¤ºä¾‹ (ç±»å‹å®‰å…¨ç‰ˆæœ¬)")
    print("=" * 80)
    
    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    test_enable_thinking_false()
    test_enable_thinking_true()
    test_different_models()
    test_multiple_questions()
    test_parameter_optimization()
    test_comparison_with_without_enable_thinking()
    
    print("=" * 80)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ")
    print("ğŸ’¡ å…³é”®å‘ç°:")
    print("   1. enable_thinking=False æ˜¯æ§åˆ¶æ€è€ƒè¿‡ç¨‹çš„å…³é”®å‚æ•°")
    print("   2. é…åˆä¸­æ–‡ç³»ç»Ÿæç¤ºè¯æ•ˆæœæ›´å¥½") 
    print("   3. æ¨èå‚æ•°: temperature=0.7, top_p=0.8, presence_penalty=1.5")
    print("   4. max_tokens å»ºè®®è®¾ç½®ä¸º 150-400 å¯¹äºç®€çŸ­å›ç­”")
    print("   5. extra_body ä¸­çš„ chat_template_kwargs æ˜¯ SGLang ç‰¹æœ‰åŠŸèƒ½")
    print("   6. OpenAI SDK å…¼å®¹æ€§è‰¯å¥½ï¼Œå¯ç›´æ¥æ›¿æ¢ API ç«¯ç‚¹")
    print("=" * 80)

if __name__ == "__main__":
    main() 